{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobileVit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4KDIM/0sCbjJe38LZO7KP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterpanw/Imageclassifier/blob/main/mobileVit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKiAkvG4bmW",
        "outputId": "52a5866f-2cdf-42dc-f4d8-90ccd838435a"
      },
      "source": [
        "pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_LmL2uz4lw4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.applications import imagenet_utils\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "tfds.disable_progress_bar()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3hTT5qJ4uDp"
      },
      "source": [
        "##Hyperparameters\n",
        "patch_size = 4\n",
        "image_size = 256\n",
        "expansion_factor = 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3I5-ggJ4yEY"
      },
      "source": [
        "##mobilevit utilities\n",
        "def conv_block(x, filters=16, kernel_size=3, strides=2):\n",
        "    conv_layer = layers.Conv2D(\n",
        "        filters, kernel_size, strides=strides, activation=tf.nn.swish, padding=\"same\"\n",
        "    )\n",
        "    return conv_layer(x)\n",
        "def inverted_residual_block(x, expanded_channels, output_channels, strides=1):\n",
        "    m = layers.Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False)(x)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    m = tf.nn.swish(m)\n",
        "\n",
        "    if strides == 2:\n",
        "        m = layers.ZeroPadding2D(padding=imagenet_utils.correct_pad(m, 3))(m)\n",
        "    m = layers.DepthwiseConv2D(\n",
        "        3, strides=strides, padding=\"same\" if strides == 1 else \"valid\", use_bias=False\n",
        "    )(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    m = tf.nn.swish(m)\n",
        "\n",
        "    m = layers.Conv2D(output_channels, 1, padding=\"same\", use_bias=False)(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "\n",
        "    if tf.math.equal(x.shape[-1], output_channels) and strides == 1:\n",
        "        return layers.Add()([m, x])\n",
        "    return m\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.swish)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "def transformer_block(x, transformer_layers, projection_dim, num_heads=2):\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, x])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.1,)\n",
        "        # Skip connection 2.\n",
        "        x = layers.Add()([x3, x2])\n",
        "\n",
        "    return x\n",
        "def mobilevit_block(x, num_blocks, projection_dim, strides=1):\n",
        "    # Local projection with convolutions.\n",
        "    local_features = conv_block(x, filters=projection_dim, strides=strides)\n",
        "    local_features = conv_block(\n",
        "        local_features, filters=projection_dim, kernel_size=1, strides=strides\n",
        "    )\n",
        "\n",
        "    # Unfold into patches and then pass through Transformers.\n",
        "    num_patches = int((local_features.shape[1] * local_features.shape[2]) / patch_size)\n",
        "    non_overlapping_patches = layers.Reshape((patch_size, num_patches, projection_dim))(\n",
        "        local_features\n",
        "    )\n",
        "    global_features = transformer_block(\n",
        "        non_overlapping_patches, num_blocks, projection_dim\n",
        "    )\n",
        "\n",
        "    # Fold into conv-like feature-maps.\n",
        "    folded_feature_map = layers.Reshape((*local_features.shape[1:-1], projection_dim))(\n",
        "        global_features\n",
        "    )\n",
        "\n",
        "    # Apply point-wise conv -> concatenate with the input features.\n",
        "    folded_feature_map = conv_block(\n",
        "        folded_feature_map, filters=x.shape[-1], kernel_size=1, strides=strides\n",
        "    )\n",
        "    local_global_features = layers.Concatenate(axis=-1)([x, folded_feature_map])\n",
        "\n",
        "    # Fuse the local and global features using a convoluion layer.\n",
        "    local_global_features = conv_block(\n",
        "        local_global_features, filters=projection_dim, strides=strides\n",
        "    )\n",
        "\n",
        "    return local_global_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKjjcomh5Cch",
        "outputId": "7ced75ad-6ce3-4cd1-81a8-99305c7c114b"
      },
      "source": [
        "##More on the MobileViT block:\n",
        "def create_mobilevit(num_classes=5):\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Initial conv-stem -> MV2 block.\n",
        "    x = conv_block(x, filters=16)\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=16 * expansion_factor, output_channels=16\n",
        "    )\n",
        "\n",
        "    # Downsampling with MV2 block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=16 * expansion_factor, output_channels=24, strides=2\n",
        "    )\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=24 * expansion_factor, output_channels=24\n",
        "    )\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=24 * expansion_factor, output_channels=24\n",
        "    )\n",
        "\n",
        "    # First MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=24 * expansion_factor, output_channels=48, strides=2\n",
        "    )\n",
        "    x = mobilevit_block(x, num_blocks=2, projection_dim=64)\n",
        "\n",
        "    # Second MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=64 * expansion_factor, output_channels=64, strides=2\n",
        "    )\n",
        "    x = mobilevit_block(x, num_blocks=4, projection_dim=80)\n",
        "\n",
        "    # Third MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=80 * expansion_factor, output_channels=80, strides=2\n",
        "    )\n",
        "    x = mobilevit_block(x, num_blocks=3, projection_dim=96)\n",
        "    x = conv_block(x, filters=320, kernel_size=1, strides=1)\n",
        "\n",
        "    # Classification head.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "mobilevit_xxs = create_mobilevit()\n",
        "mobilevit_xxs.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rescaling (Rescaling)           (None, 256, 256, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 128, 128, 16) 448         rescaling[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 32) 512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 128, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu (TFOpLambda)         (None, 128, 128, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d (DepthwiseConv (None, 128, 128, 32) 288         tf.nn.silu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         depthwise_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_1 (TFOpLambda)       (None, 128, 128, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 16) 512         tf.nn.silu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 128, 128, 16) 0           batch_normalization_2[0][0]      \n",
            "                                                                 conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 512         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_2 (TFOpLambda)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 129, 129, 32) 0           tf.nn.silu_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_1 (DepthwiseCo (None, 64, 64, 32)   288         zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 32)   128         depthwise_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_3 (TFOpLambda)       (None, 64, 64, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 24)   768         tf.nn.silu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 24)   96          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 48)   1152        batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_4 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_2 (DepthwiseCo (None, 64, 64, 48)   432         tf.nn.silu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 48)   192         depthwise_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_5 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 24)   1152        tf.nn.silu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 24)   96          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64, 64, 24)   0           batch_normalization_8[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 48)   1152        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_6 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_3 (DepthwiseCo (None, 64, 64, 48)   432         tf.nn.silu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 48)   192         depthwise_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_7 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 24)   1152        tf.nn.silu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 24)   96          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 64, 24)   0           batch_normalization_11[0][0]     \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 48)   1152        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 64, 64, 48)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_8 (TFOpLambda)       (None, 64, 64, 48)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 65, 65, 48)   0           tf.nn.silu_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_4 (DepthwiseCo (None, 32, 32, 48)   432         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 48)   192         depthwise_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_9 (TFOpLambda)       (None, 32, 32, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 48)   2304        tf.nn.silu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 64)   27712       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 64)   4160        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 4, 256, 64)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization (LayerNorma (None, 4, 256, 64)   128         reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention (MultiHead (None, 4, 256, 64)   33216       layer_normalization[0][0]        \n",
            "                                                                 layer_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 4, 256, 64)   0           multi_head_attention[0][0]       \n",
            "                                                                 reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNor (None, 4, 256, 64)   128         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4, 256, 128)  8320        layer_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 4, 256, 128)  0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4, 256, 64)   8256        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4, 256, 64)   0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 256, 64)   0           dropout_1[0][0]                  \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNor (None, 4, 256, 64)   128         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_1 (MultiHe (None, 4, 256, 64)   33216       layer_normalization_2[0][0]      \n",
            "                                                                 layer_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 256, 64)   0           multi_head_attention_1[0][0]     \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNor (None, 4, 256, 64)   128         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4, 256, 128)  8320        layer_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 4, 256, 128)  0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4, 256, 64)   8256        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 4, 256, 64)   0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 256, 64)   0           dropout_3[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 32, 32, 64)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 48)   3120        reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 96)   0           batch_normalization_14[0][0]     \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 64)   55360       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 128)  8192        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_10 (TFOpLambda)      (None, 32, 32, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 33, 33, 128)  0           tf.nn.silu_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_5 (DepthwiseCo (None, 16, 16, 128)  1152        zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         depthwise_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_11 (TFOpLambda)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 64)   8192        tf.nn.silu_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 80)   46160       batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 80)   6480        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 4, 64, 80)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNor (None, 4, 64, 80)    160         reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_2 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_4[0][0]      \n",
            "                                                                 layer_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 64, 80)    0           multi_head_attention_2[0][0]     \n",
            "                                                                 reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNor (None, 4, 64, 80)    160         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4, 64, 160)   12960       layer_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 4, 64, 160)   0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4, 64, 80)    12880       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 4, 64, 80)    0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 64, 80)    0           dropout_5[0][0]                  \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNor (None, 4, 64, 80)    160         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_3 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_6[0][0]      \n",
            "                                                                 layer_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 4, 64, 80)    0           multi_head_attention_3[0][0]     \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_7 (LayerNor (None, 4, 64, 80)    160         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 4, 64, 160)   12960       layer_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 4, 64, 160)   0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 4, 64, 80)    12880       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 4, 64, 80)    0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 4, 64, 80)    0           dropout_7[0][0]                  \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_8 (LayerNor (None, 4, 64, 80)    160         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_4 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_8[0][0]      \n",
            "                                                                 layer_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 4, 64, 80)    0           multi_head_attention_4[0][0]     \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_9 (LayerNor (None, 4, 64, 80)    160         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 4, 64, 160)   12960       layer_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 4, 64, 160)   0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 4, 64, 80)    12880       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 4, 64, 80)    0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 4, 64, 80)    0           dropout_9[0][0]                  \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_10 (LayerNo (None, 4, 64, 80)    160         add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_5 (MultiHe (None, 4, 64, 80)    51760       layer_normalization_10[0][0]     \n",
            "                                                                 layer_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 64, 80)    0           multi_head_attention_5[0][0]     \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_11 (LayerNo (None, 4, 64, 80)    160         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 4, 64, 160)   12960       layer_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 4, 64, 160)   0           dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 4, 64, 80)    12880       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 4, 64, 80)    0           dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 4, 64, 80)    0           dropout_11[0][0]                 \n",
            "                                                                 add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 16, 16, 80)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   5184        reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 80)   92240       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 160)  12800       conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 160)  640         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_12 (TFOpLambda)      (None, 16, 16, 160)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 17, 17, 160)  0           tf.nn.silu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_6 (DepthwiseCo (None, 8, 8, 160)    1440        zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 160)    640         depthwise_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.silu_13 (TFOpLambda)      (None, 8, 8, 160)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 80)     12800       tf.nn.silu_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 80)     320         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 96)     69216       batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 96)     9312        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 4, 16, 96)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_12 (LayerNo (None, 4, 16, 96)    192         reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_6 (MultiHe (None, 4, 16, 96)    74400       layer_normalization_12[0][0]     \n",
            "                                                                 layer_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 4, 16, 96)    0           multi_head_attention_6[0][0]     \n",
            "                                                                 reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_13 (LayerNo (None, 4, 16, 96)    192         add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 4, 16, 192)   18624       layer_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 4, 16, 192)   0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 4, 16, 96)    18528       dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 4, 16, 96)    0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 4, 16, 96)    0           dropout_13[0][0]                 \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_14 (LayerNo (None, 4, 16, 96)    192         add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_7 (MultiHe (None, 4, 16, 96)    74400       layer_normalization_14[0][0]     \n",
            "                                                                 layer_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 4, 16, 96)    0           multi_head_attention_7[0][0]     \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_15 (LayerNo (None, 4, 16, 96)    192         add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 4, 16, 192)   18624       layer_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 4, 16, 192)   0           dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 4, 16, 96)    18528       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 4, 16, 96)    0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 4, 16, 96)    0           dropout_15[0][0]                 \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_16 (LayerNo (None, 4, 16, 96)    192         add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_8 (MultiHe (None, 4, 16, 96)    74400       layer_normalization_16[0][0]     \n",
            "                                                                 layer_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 4, 16, 96)    0           multi_head_attention_8[0][0]     \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_17 (LayerNo (None, 4, 16, 96)    192         add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 4, 16, 192)   18624       layer_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 4, 16, 192)   0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 4, 16, 96)    18528       dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 4, 16, 96)    0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 4, 16, 96)    0           dropout_17[0][0]                 \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 8, 8, 96)     0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 80)     7760        reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 160)    0           batch_normalization_20[0][0]     \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 96)     138336      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 320)    31040       conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 320)          0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 5)            1605        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 1,307,621\n",
            "Trainable params: 1,305,077\n",
            "Non-trainable params: 2,544\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyjrT5vz5HZI"
      },
      "source": [
        "## Dataset preparation\n",
        "batch_size = 64       # 原文中 batch_size = 64, 由于电脑算力不行，改为8才能正常运行\n",
        "auto = tf.data.AUTOTUNE\n",
        "resize_bigger = 280\n",
        "num_classes = 5\n",
        "\n",
        "def preprocess_dataset(is_training=True):\n",
        "    def _pp(image, label):\n",
        "        if is_training:\n",
        "            # Resize to a bigger spatial resolution and take the random\n",
        "            # crops.\n",
        "            image = tf.image.resize(image, (resize_bigger, resize_bigger))\n",
        "            image = tf.image.random_crop(image, (image_size, image_size, 3))\n",
        "            image = tf.image.random_flip_left_right(image)\n",
        "        else:\n",
        "            image = tf.image.resize(image, (image_size, image_size))\n",
        "        label = tf.one_hot(label, depth=num_classes)\n",
        "        return image, label\n",
        "\n",
        "    return _pp\n",
        "def prepare_dataset(dataset, is_training=True):\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.map(preprocess_dataset(is_training), num_parallel_calls=auto)\n",
        "    return dataset.batch(batch_size).prefetch(auto)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKug2X_W5TDT",
        "outputId": "b8b9e620-5697-466f-ab4d-4064a3c8b360"
      },
      "source": [
        "## Load and prepare the dataset\n",
        "train_dataset, val_dataset = tfds.load(\n",
        "    \"tf_flowers\", split=[\"train[:90%]\", \"train[90%:]\"], as_supervised=True\n",
        ")\n",
        "\n",
        "num_train = train_dataset.cardinality()\n",
        "num_val = val_dataset.cardinality()\n",
        "print(f\"Number of training examples: {num_train}\")\n",
        "print(f\"Number of validation examples: {num_val}\")\n",
        "\n",
        "train_dataset = prepare_dataset(train_dataset, is_training=True)\n",
        "val_dataset = prepare_dataset(val_dataset, is_training=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 3303\n",
            "Number of validation examples: 367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db8yWGge5V82",
        "outputId": "a9bd9263-c21d-4b8f-cce6-ac2516f194fb"
      },
      "source": [
        "## Train a MobileViT (XXS) model\n",
        "\n",
        "learning_rate = 0.002\n",
        "label_smoothing_factor = 0.1\n",
        "epochs = 30\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing_factor)\n",
        "\n",
        "def run_experiment(epochs=epochs):\n",
        "    mobilevit_xxs = create_mobilevit(num_classes=num_classes)\n",
        "    mobilevit_xxs.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "\n",
        "    #checkpoint_filepath = \"/tmp/checkpoint\"    相对路径要加./xxx/...\n",
        "    checkpoint_filepath = \"./tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    mobilevit_xxs.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=epochs,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "    mobilevit_xxs.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = mobilevit_xxs.evaluate(val_dataset)\n",
        "    print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    return mobilevit_xxs\n",
        "\n",
        "mobilevit_xxs = run_experiment()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "52/52 [==============================] - 97s 2s/step - loss: 1.3343 - accuracy: 0.4735 - val_loss: 1.7260 - val_accuracy: 0.1907\n",
            "Epoch 2/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 1.1637 - accuracy: 0.6022 - val_loss: 1.9324 - val_accuracy: 0.1907\n",
            "Epoch 3/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 1.0764 - accuracy: 0.6458 - val_loss: 2.2677 - val_accuracy: 0.1907\n",
            "Epoch 4/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 1.0075 - accuracy: 0.6909 - val_loss: 2.2792 - val_accuracy: 0.1907\n",
            "Epoch 5/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.9420 - accuracy: 0.7254 - val_loss: 2.6014 - val_accuracy: 0.1907\n",
            "Epoch 6/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.9247 - accuracy: 0.7351 - val_loss: 3.0619 - val_accuracy: 0.1907\n",
            "Epoch 7/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.8803 - accuracy: 0.7593 - val_loss: 2.5203 - val_accuracy: 0.1907\n",
            "Epoch 8/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.8439 - accuracy: 0.7705 - val_loss: 3.3974 - val_accuracy: 0.1907\n",
            "Epoch 9/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.8297 - accuracy: 0.7832 - val_loss: 2.7936 - val_accuracy: 0.2262\n",
            "Epoch 10/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.8019 - accuracy: 0.7969 - val_loss: 1.8471 - val_accuracy: 0.4251\n",
            "Epoch 11/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7801 - accuracy: 0.8120 - val_loss: 1.0081 - val_accuracy: 0.7112\n",
            "Epoch 12/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.8001 - accuracy: 0.7938 - val_loss: 0.8598 - val_accuracy: 0.7629\n",
            "Epoch 13/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7547 - accuracy: 0.8208 - val_loss: 1.1321 - val_accuracy: 0.6594\n",
            "Epoch 14/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7587 - accuracy: 0.8253 - val_loss: 0.8104 - val_accuracy: 0.7929\n",
            "Epoch 15/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7280 - accuracy: 0.8374 - val_loss: 0.9268 - val_accuracy: 0.7411\n",
            "Epoch 16/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7481 - accuracy: 0.8277 - val_loss: 0.9413 - val_accuracy: 0.7357\n",
            "Epoch 17/30\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.7322 - accuracy: 0.8347 - val_loss: 0.7040 - val_accuracy: 0.8392\n",
            "Epoch 18/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7050 - accuracy: 0.8465 - val_loss: 1.0455 - val_accuracy: 0.7166\n",
            "Epoch 19/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7032 - accuracy: 0.8471 - val_loss: 0.9768 - val_accuracy: 0.7030\n",
            "Epoch 20/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6956 - accuracy: 0.8544 - val_loss: 0.8016 - val_accuracy: 0.8011\n",
            "Epoch 21/30\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.7404 - accuracy: 0.8320 - val_loss: 1.5015 - val_accuracy: 0.5804\n",
            "Epoch 22/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.7260 - accuracy: 0.8429 - val_loss: 1.6491 - val_accuracy: 0.6158\n",
            "Epoch 23/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6866 - accuracy: 0.8589 - val_loss: 0.9698 - val_accuracy: 0.7357\n",
            "Epoch 24/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6730 - accuracy: 0.8668 - val_loss: 0.7895 - val_accuracy: 0.8011\n",
            "Epoch 25/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6490 - accuracy: 0.8780 - val_loss: 0.9958 - val_accuracy: 0.7221\n",
            "Epoch 26/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6394 - accuracy: 0.8892 - val_loss: 0.9149 - val_accuracy: 0.7766\n",
            "Epoch 27/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6489 - accuracy: 0.8828 - val_loss: 0.8539 - val_accuracy: 0.8011\n",
            "Epoch 28/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6326 - accuracy: 0.8865 - val_loss: 0.8371 - val_accuracy: 0.7929\n",
            "Epoch 29/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6252 - accuracy: 0.8916 - val_loss: 0.8630 - val_accuracy: 0.7929\n",
            "Epoch 30/30\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.6233 - accuracy: 0.8880 - val_loss: 1.0061 - val_accuracy: 0.7302\n",
            "6/6 [==============================] - 2s 383ms/step - loss: 0.7040 - accuracy: 0.8392\n",
            "Validation accuracy: 83.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VZ1elkOC5xlY",
        "outputId": "409a1a9d-fdcf-4121-828e-50f630e22d85"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUSsCY8aL2_k",
        "outputId": "6a7cea35-975a-4f70-f20a-caed0416f3be"
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 27 14:37:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    57W / 149W |  11077MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHhHBq9PL6iZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}