{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOX5hO0U/HSIniqvW/tR277",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterpanw/Imageclassifier/blob/main/Resnet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QItaskvxB8J"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, Sequential, optimizers, metrics   # Sequential 序贯模型\n",
        "import os    # os库  用于访问操作系统的标准库 处理文件和目录\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_apuK45xSzk",
        "outputId": "b910825c-1c79-424a-b2c6-0e00dd92e68a"
      },
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "os.environ['TF_CPP_MIN_LEVEL'] = '2'\n",
        "assert tf.__version__.startswith('2.')  # assert<表达式>  用于测试<表达式>的值，如果值为true正常通过，值为false则报错\"AssertError\"\n",
        "\n",
        "## 配置超参数\n",
        "batch_size = 128\n",
        "optimizer = optimizers.Adam(lr=0.0001)     #优化器\n",
        "epochs = 20"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xktHbSO5xWgM",
        "outputId": "25963b33-1de1-475c-e0fa-621fe4e0028d"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "print(\"train_shape:\", x_train.shape, y_train.shape)\n",
        "y_train = tf.squeeze(y_train,  axis=1)\n",
        "y_test = tf.squeeze(y_test, axis=1)\n",
        "print(\"train_shape:\", x_train.shape, y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n",
            "train_shape: (50000, 32, 32, 3) (50000, 1)\n",
            "train_shape: (50000, 32, 32, 3) (50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APYKr3YvxeGn"
      },
      "source": [
        "def preprocess(x,y):\n",
        "    x = tf.cast(x, dtype=tf.float32)/255.\n",
        "    y = tf.cast(y, dtype=tf.int32)\n",
        "    return x, y\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_db = train_db.map(preprocess).shuffle(50000).batch(batch_size)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_db = test_db.map(preprocess).batch(batch_size)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJE5sX0exqWJ"
      },
      "source": [
        "####   构建 简单层\n",
        "class BasicBlock(layers.Layer):\n",
        "    def __init__(self, filter_num, strides=1):\n",
        "        super(BasicBlock, self).__init__()      # super()调用父类\n",
        "\n",
        "        \"\"\"\n",
        "        conv2d -> batchnormalization -> relu activation\n",
        "        \"\"\"\n",
        "        #unit1\n",
        "        self.conv1 = layers.Conv2D(filters=filter_num, kernel_size=(3, 3), strides=strides, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.Activation('relu')\n",
        "\n",
        "        #unit2\n",
        "        self.conv2 = layers.Conv2D(filter_num, (3, 3), strides=1, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.downsample = Sequential()\n",
        "            self.downsample.add(layers.Conv2D(filter_num, (1, 1), strides=strides))\n",
        "        else:\n",
        "            self.downsample = lambda x : x\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x = inputs\n",
        "        # 前向传播\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        # 下采样\n",
        "        down = self.downsample(x)\n",
        "        # f(x)+x  对张量求和\n",
        "        out_put = layers.add([out, down])\n",
        "        out_put = tf.nn.relu(out_put)\n",
        "        return out_put"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcz0sMlCxwjG"
      },
      "source": [
        "class ResNet(keras.Model):\n",
        "    def __init__(self, layers_dims, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        #预处理层\n",
        "        self.stem = Sequential([layers.Conv2D(64, (3, 3), strides=(1, 1)),\n",
        "                                layers.BatchNormalization(),\n",
        "                                layers.Activation('relu'),\n",
        "                                layers.MaxPool2D((2, 2), strides=(1, 1), padding='same')])\n",
        "        #接上4个ResBlock层\n",
        "        self.resblock1 = self.ResBlock(64, blocks=layers_dims[0])\n",
        "        self.resblock2 = self.ResBlock(128, blocks=layers_dims[1], strides=2)\n",
        "        self.resblock3 = self.ResBlock(256, blocks=layers_dims[2], strides=2)\n",
        "        self.resblock4 = self.ResBlock(512, blocks=layers_dims[3], strides=2)\n",
        "\n",
        "        #分类层\n",
        "        self.avgpool = layers.GlobalAveragePooling2D()\n",
        "        self.fc = layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        out = self.stem(inputs)\n",
        "        out = self.resblock1(out)\n",
        "        out = self.resblock2(out)\n",
        "        out = self.resblock3(out)\n",
        "        out = self.resblock4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def ResBlock(self, filter_nums, blocks, strides=1):\n",
        "        resblock = Sequential()\n",
        "        resblock.add(BasicBlock(filter_nums, strides))\n",
        "        #  _ 在for循环中只是一个循环标志 类似于i, j\n",
        "        for _ in range(blocks):\n",
        "            resblock.add(BasicBlock(filter_nums, strides=1))\n",
        "        return resblock"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9cQRwHhx5GO",
        "outputId": "99422278-4587-4471-9667-9bac5f6dd41a"
      },
      "source": [
        "# ResNet-18 18层卷积层   1+4*2*2+1   一个ResBlock包含两个BasicBlock，一个BasicBlock包含两个卷积层\n",
        "resnet_18 = ResNet([2, 2, 2, 2])\n",
        "\n",
        "\n",
        "# 测试网络输出shape\n",
        "# x = tf.random.normal((1, 32, 32, 3))\n",
        "# out = resnet_18(x)\n",
        "# print(out.shape)\n",
        "\n",
        "# 输出网络结构\n",
        "resnet_18.build(input_shape=(None, 32, 32, 3))\n",
        "# 输出参数 Param 计算过程\n",
        "resnet_18.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"res_net\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 30, 30, 64)        2048      \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 30, 30, 64)        223104    \n",
            "                                                                 \n",
            " sequential_2 (Sequential)   (None, 15, 15, 128)       823168    \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 8, 8, 256)         3284736   \n",
            "                                                                 \n",
            " sequential_6 (Sequential)   (None, 4, 4, 512)         13123072  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  multiple                 0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,461,258\n",
            "Trainable params: 17,449,610\n",
            "Non-trainable params: 11,648\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QMwC4ZFox0ik",
        "outputId": "dcea401c-cfdb-4f46-ad53-b04f2afe1c98"
      },
      "source": [
        "def main():\n",
        "    for epoch in range(epochs):\n",
        "        for step, (x, y) in enumerate(train_db):       # 在训练集上训练 train_db\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = resnet_18(x)   # logits是网络输出层的输出\n",
        "                y_onehot = tf.one_hot(y, depth=10)   # 一维向量，标签\n",
        "                # tf.losses.categorical_crossentropy   先是正确值 再是预测值 否则loss优化会出错\n",
        "                loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
        "                loss = tf.reduce_mean(loss)\n",
        "            grads = tape.gradient(loss, resnet_18.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, resnet_18.trainable_variables))\n",
        "\n",
        "\n",
        "            if step % 10 == 0:\n",
        "                print(epoch, step, 'loss:', float(loss))\n",
        "\n",
        "            \"\"\"\n",
        "            ##  tf.argmax(input, axis)会根据axis取值的不同返回每行或者每列最大值的索引，\n",
        "            #  当axis=0时：比较每一列的元素，输出每一列最大元素所在的索引数组\n",
        "            #  当axis=1时：比较每一行的元素，输出每一行最大元素所在的索引数组\n",
        "            ## tf.equal(x, y) 用来判断两个矩阵或者向量相等的元素，相等返回true，反之返回false，返回的值得矩阵的维度=x=y的维度\n",
        "            ## tf.reduce_mean() 用来计算张量(tensor)沿着指定的数轴(tensor的某一维度)上的平均值，主要用于降维或者计算tensor的平均值\n",
        "            \"\"\"\n",
        "            if step % 50 == 0:\n",
        "                total_correct = 0\n",
        "                total_num = 0\n",
        "                for step, (x, y) in enumerate(test_db):         # 测试集 test_db\n",
        "                    logits = resnet_18(x)   # resnet网络的输出结果\n",
        "                    prob = tf.nn.softmax(logits, axis=1)    ## 经过softmax以后的 概率\n",
        "                    pred = tf.cast(tf.argmax(prob, axis=1), dtype=tf.int32)   ## 每一行的最大概率 ，\n",
        "                    correct = tf.reduce_sum(tf.cast(tf.equal(pred, y), dtype=tf.int32))\n",
        "\n",
        "                    total_correct += correct\n",
        "                    total_num += x.shape[0]\n",
        "                acc = total_correct/total_num    # 计算 准确率\n",
        "                print(epoch, step, 'acc:', float(acc))\n",
        "                resnet_18.save_weights('./checkpoint/weights.ckpt')\n",
        "                print('save weights')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 loss: 2.321587562561035\n",
            "0 78 acc: 0.1\n",
            "save weights\n",
            "0 10 loss: 2.2805662155151367\n",
            "0 20 loss: 2.2072219848632812\n",
            "0 30 loss: 2.1455698013305664\n",
            "0 40 loss: 2.1353025436401367\n",
            "0 50 loss: 2.0188426971435547\n",
            "0 78 acc: 0.2423\n",
            "save weights\n",
            "0 60 loss: 1.9447022676467896\n",
            "0 70 loss: 1.8268839120864868\n",
            "0 80 loss: 1.8992937803268433\n",
            "0 90 loss: 1.7223906517028809\n",
            "0 100 loss: 1.9277873039245605\n",
            "0 78 acc: 0.3011\n",
            "save weights\n",
            "0 110 loss: 1.7918689250946045\n",
            "0 120 loss: 1.8325366973876953\n",
            "0 130 loss: 1.9281809329986572\n",
            "0 140 loss: 1.6651159524917603\n",
            "0 150 loss: 1.634725570678711\n",
            "0 78 acc: 0.3739\n",
            "save weights\n",
            "0 160 loss: 1.5836471319198608\n",
            "0 170 loss: 1.7048349380493164\n",
            "0 180 loss: 1.6841905117034912\n",
            "0 190 loss: 1.506029486656189\n",
            "0 200 loss: 1.6742441654205322\n",
            "0 78 acc: 0.4013\n",
            "save weights\n",
            "0 210 loss: 1.6577266454696655\n",
            "0 220 loss: 1.6538832187652588\n",
            "0 230 loss: 1.6991896629333496\n",
            "0 240 loss: 1.6285042762756348\n",
            "0 250 loss: 1.6547770500183105\n",
            "0 78 acc: 0.3985\n",
            "save weights\n",
            "0 260 loss: 1.4578973054885864\n",
            "0 270 loss: 1.7212238311767578\n",
            "0 280 loss: 1.503261923789978\n",
            "0 290 loss: 1.5573490858078003\n",
            "0 300 loss: 1.513398289680481\n",
            "0 78 acc: 0.446\n",
            "save weights\n",
            "0 310 loss: 1.5278176069259644\n",
            "0 320 loss: 1.541900634765625\n",
            "0 330 loss: 1.5860568284988403\n",
            "0 340 loss: 1.4234554767608643\n",
            "0 350 loss: 1.5078227519989014\n",
            "0 78 acc: 0.4616\n",
            "save weights\n",
            "0 360 loss: 1.4739937782287598\n",
            "0 370 loss: 1.6389657258987427\n",
            "0 380 loss: 1.378931999206543\n",
            "0 390 loss: 1.627906084060669\n",
            "1 0 loss: 1.3161375522613525\n",
            "1 78 acc: 0.484\n",
            "save weights\n",
            "1 10 loss: 1.5776052474975586\n",
            "1 20 loss: 1.4292998313903809\n",
            "1 30 loss: 1.423476219177246\n",
            "1 40 loss: 1.3745367527008057\n",
            "1 50 loss: 1.3548872470855713\n",
            "1 78 acc: 0.5096\n",
            "save weights\n",
            "1 60 loss: 1.400038242340088\n",
            "1 70 loss: 1.355551838874817\n",
            "1 80 loss: 1.460453748703003\n",
            "1 90 loss: 1.410762071609497\n",
            "1 100 loss: 1.2247188091278076\n",
            "1 78 acc: 0.5118\n",
            "save weights\n",
            "1 110 loss: 1.1255393028259277\n",
            "1 120 loss: 1.3358203172683716\n",
            "1 130 loss: 1.395545482635498\n",
            "1 140 loss: 1.3234022855758667\n",
            "1 150 loss: 1.1718201637268066\n",
            "1 78 acc: 0.5272\n",
            "save weights\n",
            "1 160 loss: 1.2285147905349731\n",
            "1 170 loss: 1.1306798458099365\n",
            "1 180 loss: 1.244895100593567\n",
            "1 190 loss: 1.2251240015029907\n",
            "1 200 loss: 1.1305574178695679\n",
            "1 78 acc: 0.533\n",
            "save weights\n",
            "1 210 loss: 1.2070773839950562\n",
            "1 220 loss: 1.2779879570007324\n",
            "1 230 loss: 1.2525599002838135\n",
            "1 240 loss: 1.2746069431304932\n",
            "1 250 loss: 1.0225306749343872\n",
            "1 78 acc: 0.5591\n",
            "save weights\n",
            "1 260 loss: 1.2398583889007568\n",
            "1 270 loss: 1.263676404953003\n",
            "1 280 loss: 1.2201635837554932\n",
            "1 290 loss: 1.3576303720474243\n",
            "1 300 loss: 1.3788962364196777\n",
            "1 78 acc: 0.5451\n",
            "save weights\n",
            "1 310 loss: 1.2674182653427124\n",
            "1 320 loss: 1.1637035608291626\n",
            "1 330 loss: 1.5075613260269165\n",
            "1 340 loss: 1.2070040702819824\n",
            "1 350 loss: 1.1623529195785522\n",
            "1 78 acc: 0.58\n",
            "save weights\n",
            "1 360 loss: 1.1791785955429077\n",
            "1 370 loss: 1.1718518733978271\n",
            "1 380 loss: 1.0327504873275757\n",
            "1 390 loss: 1.1866518259048462\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-080cec8e698e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-080cec8e698e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;31m# 在训练集上训练 train_db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# logits是网络输出层的输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vv3ooIzyIMQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}